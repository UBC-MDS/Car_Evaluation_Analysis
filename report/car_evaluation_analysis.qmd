---
title: "Predicing Level of Acceptability of Cars using Machine Learning"
author: "Danish Karlin Isa, Nicholas Varabioff, Ximin Xu & Zuer Zhong"
date: today
jupyter: python3
format: 
    html:
        toc: true
        toc-depth: 3
    pdf:
        toc: true
        toc-depth: 3
bibliography: references.bib
execute:
    echo: false
    warning: false
---

```{python}
# imports
import pandas as pd
from IPython.display import Markdown, display
from tabulate import tabulate
import altair as alt
from sklearn.model_selection import train_test_split
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OrdinalEncoder
import pickle
import pandera as pa
```
```{python}
test_scores_df = pd.read_csv("../results/tables/test_scores.csv").round(2)
with open('../results/models/car_analysis.pickle', 'rb') as f:
    car_eva = pickle.load(f)

```

## Summary

In this project, we attempt to predict the level of acceptability of cars by building a machine learning model in Python [@Python]. 
We use a data created by the efforts of M. Bohanec in the late 1980s. It is sourced from the UCI Machine Learning Repository and is publicly available for research. Every features and target in this dataset are all encoded by one-hot encoder for data analysis.
To choose the best model for this task, we utilised several common machine learning models, 
and found out that the SVM RBF classifier achieved the best train and cross-validation scores, with a test accuracy of 0.952. 
The SVM RBF model also showed exceptional ability in determining the acceptability of cars as seen in accuracy. With an accuracy of 0.99 on test data. 
This makes the SVM RBF model a solid choice for this project.

## Introduction

The Car Evaluation Dataset was created as part of efforts to understand the factors that affect the acceptability of cars among consumers. These factors include buying price of a car, maintenance costs, passenger and luggage capacity, and safety. The goal of this project is to develop a machine learning model that can evaluate the quality of a car based on its attributes to help buyers make a more informed decision for their next car purchase.

## Methods

### Data

The dataset that was used in this project is of Car Evaluation Database [@dataset] created by the efforts of M. Bohanec in the late 1980s. It is sourced from the UCI Machine Learning Repository and is publicly available for research. 

Each row in the dataset details a car’s attributes (each feature is of categorical data type with several levels), which includes:

-   Buying price: `low`, `med`, `high`, `vhigh`
-   Maintenance cost: `low`, `med`, `high`, `vhigh`
-   Number of doors: `2`, `3`, `4`, `5more`
-   Seating capacity: `2`, `4`, `more`
-   Boot size: `small`, `med`, `big`
-   Safety rating: `low`, `med`, `high`


### Exploratory Data Analysis

Exploratory data analysis was carried out on the train dataset. From @fig-featurecounts, we can see the counts of records by target and category was visualised to gain a better idea of the dataset.

![Distribution of Features by Class](../results/figures/feature_counts_by_class.png){#fig-featurecounts width=70%}

Through this analysis, we can see that examples with target class `unacceptable` represent a large proportion of the dataset.

### Preprocessing of Dataset for Machine Learning

We preprocess the dataset to prepare it for machine learning: 

- Transform categorical features using `OrdinalEncoder` from scikit-learn 
- Split the dataset into training and testing sets

### Model Selection

The core of this project is choosing the appropriate machine learning model. 
Thus, several machine learning models from scikit-learn [@scikit-learn] will be evaluated using cross-validation. 
The models evaluated are:

- `DummyClassifier` (Dummy), which serves as a baseline to compare the performance of other models,
- `DecisionTreeClassifier` (Decision Tree),
- `KNeighboursClassifier` (KNN),
- `SVC` with RBF kernel (SVM RBF),
- Naive Bayes using `MultinomialNB` (Naive Bayes), and
- `LogisticRegression` (Logistic Regression).

```{python}
#| label: tbl-model_selection_results
#| tbl-cap: Results of model selection conducted using cross-validation

model_selection_results = pd.read_csv("../results/tables/model_selection_results.csv").round(3)
Markdown(model_selection_results.to_markdown(index=False))
```

The results of the model selection is shown in [@tbl-model_selection_results].
According to the results, SVM RBF achieved high train and cross-validation scores of `{python} model_selection_results['Mean train score'][3]` and `{python} model_selection_results['Mean CV score'][3]` respectively, 
suggesting it is the best model for generalising unseen data. 

While the Decision Tree model yielded the best train and cross-validation scores, 
the perfect train score suggests that the model has overfitted to the data.
Therefore, we will be using SVM RBF for this project.

### Model Optimisation

With the best model identified, the next step was to improve its performance through hyperparameter optimization. Using RandomizedSearchCV, a range of values for the SVM’s hyperparameters C and gamma were explored. This approach allowed for an efficient and thorough search across the parameter space, and results in an optimal esitimator to use.

The visualizations below, including a heatmap (@fig-heatmaptuning) of test scores obtained during hyperparameter optimization. This interpretability aids in understanding which parameters are most critical and how sensitive the model is to these settings.

![Heatmap of test scores obtained during hyperparameter optimisation](../results/figures/car_hyperparameter.png){#fig-heatmaptuning width=70%}

We observed that the best hyperparameter of `C` and `gamma` are `{python} car_eva.best_params_['svc__C']` and `{python} car_eva.best_params_['svc__gamma']` respectively. 
All categorical features were passed through `OrdinalEncoder` prior to model fitting. 
The Python programming language [@Python] and the following Python packages were used to perform the analysis: numpy [@harris2020array], Pandas [@mckinney-proc-scipy-2010], matplotlib [@Hunter:2007], scikit-learn [@scikit-learn].
The code used to perform the analysis and create this report can be found here: [https://github.com/UBC-MDS/Car_Evaluation_Analysis/blob/main/scripts](https://github.com/UBC-MDS/Car_Evaluation_Analysis/blob/main/scripts)

## Results & Discussion

After performing hyperparameter optimisation, the SVM RBF model manage to achieve the best score of `{python} test_scores_df['accuracy'].values[0]` on the test.
This suggests the model has been generalised well, with high scores on both the train and test sets.

To further improve the model's utility, several changes can be made.
One such change is feeding the model with features that are not just categorical.
Instead, for features such as buying price, maintenance cost and safety features, numeric data should be used.
At the same time, more features can be included, such as the type of car and and fuel efficiency ratings.

By allowing the model to take in more complex data, this may allow the model to make more accurate predictions to let customers make a more informed choice when purchasing a new car.

## References
