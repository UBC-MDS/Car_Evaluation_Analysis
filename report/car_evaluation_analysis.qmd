---
title: Predicing Level of Acceptability of Cars using Machine Learning
author: " Danish Karlin Isa & Nicholas Varabioff & Ximin Xu & Zuer Zhong"
date: "2024/12/06"
jupyter: python3
format: 
    html:
        toc: true
        toc-depth: 2
    pdf:
        toc: true
        toc-depth: 2
bibliography: references.bib
execute:
    echo: false
    warning: false
---


by Danish Karlin Isa, Nicholas Varabioff, Ximin Xu, Zuer Zhong


```{python}
# imports
import numpy as np
import pandas as pd
import altair as alt
from sklearn.model_selection import train_test_split
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OrdinalEncoder
import pickle
from deepchecks.tabular import Dataset
from deepchecks.checks import ClassImbalance, FeatureLabelCorrelation, FeatureFeatureCorrelation
import pandera as pa
```
```{python}
test_scores_df = pd.read_csv("../results/tables/test_scores.csv").round(2)
with open('../results/models/car_analysis.pickle', 'rb') as f:
    car_eva = pickle.load(f)
```
## Summary

In this project, we attempt to predict the level of acceptability of cars by building a machine learning model.
To choose the best model for this task, 
we utilised several common machine learning models, 
and found out that the SVM RBF classifier achieved the best train and cross-validation scores,
with a test accuracy of 0.952.
On the 346 test data cases, 
it correctly predicted the targets of 343 examples,
while there were only 3 examples with incorrect predicted targets.

The SVM RBF model also showed exceptional ability in determining the acceptability of cars as seen in the confusion matrix, classification reports, and relatively high scores for precision, recall and F1.
However, a slight decrease in classification precision was observed for the “good” category,
together with a relatively lower recall score of 0.86 that indicates occasional classification errors. 
Nonetheless, the results obtained from this analysis further exemplifies the ability of the SVM RBF model in handling nonlinear decision boundaries. 
This makes the SVM RBF model a solid choice for this project.



## Introduction

The Car Evaluation Dataset was created as part of efforts to understand the factors that affect the acceptability of cars among consumers. 
These factors include buying price of a car, maintenance costs, passenger and luggage capacity, and safety. 
The goal of this project is to develop a machine learning model that can evaluate the quality of a car based on its attributes to help buyers make a more informed decision for their next car purchase.

The RBF SVM model is known for its effectiveness in nonlinear classification tasks, and its use is particularly useful at navigating the complexities of car evaluation. We expected the model to perform well. In our tests, we also found that it outperformed other models such as Naive Bayes and logistic regression. Our findings suggest a potential class imbalance or capacity limitation in the model's ability to adequately capture the nuances of the “good” classes. This raises questions about the ideal modeling approach for such datasets.

## Methods


### Data

The dataset that was used in this project is of Car Evaluation Database created by the efforts of M. Bohanec and V. Rajkovic in the early 1990s. 
It is sourced from the UCI Machine Learning Repository and is publicly available for research and can be found in the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/19/car+evaluation).
Each row in the dataset details a car’s attributes (each feature is of categorical data type with several levels), which includes:

* Buying price: `low`, `med`, `high`, `vhigh`
* Maintenance cost: `low`, `med`, `high`, `vhigh`
* Number of doors: `2`, `3`, `4`, `5more`
* Seating capacity: `2`, `4`, `more`
* Boot size: `small`, `med`, `big`
* Safety rating: `low`, `med`, `high`

### Analysis
With the best model identified, the next step was to improve its performance through hyperparameter optimization. Using RandomizedSearchCV, a range of values for the SVM’s hyperparameters C and gamma were explored. This approach allowed for an efficient and thorough search across the parameter space, and results in an optimal esitimator to use.

The visualizations below, including a heatmap (@heatmap_tuning) of test scores obtained during hyperparameter optimization. This interpretability aids in understanding which parameters are most critical and how sensitive the model is to these settings.

![Heatmap of test scores obtained during hyperparameter optimisation](../results/figures/car_hyperparameter.png){#heatmap_tuning, width=100%}

We observed that the best hyperparameter of $C$ and $gamma$ are `{python} car_eva.best_params_['svc__C']` and `{python} car_eva.best_params_['svc__gamma']`. All categorical features are one hot encoded prior to model fitting. The Python programming language [@Python] and the following Python packages were used to perform the analysis: numpy [@harris2020array], Pandas [@mckinney-proc-scipy-2010], matplotlib [@Hunter:2007], scikit-learn [@scikit-learn].  The code used to perform the analysis and create this report can be found here: https://github.com/UBC-MDS/Car_Evaluation_Analysis/blob/main/scripts

## Results & Discussion

After performing hyperparameter optimisation, the RBF SVM model with `C=100.0` and `gamma=0.1` achieved the best performance on the test set with a score of `{python} test_scores_df['accuracy'].values[0]`.
This suggests the model has been generalised well, with high scores on both the train and test sets.

To further improve the model's utility, several changes can be made.
One such change is feeding the model with features that are not just categorical.
Instead, for features such as buying price, maintenance cost and safety features, numeric data should be used.
At the same time, more features can be included, such as the type of car and and fuel efficiency ratings.

By allowing the model to take in more complex data, this may allow the model to make more accurate predictions to let customers make a more informed choice when purchasing a new car.

```{python}
# import raw data
# data located at https://archive.ics.uci.edu/dataset/19/car+evaluation

colnames = ['buying','maint','doors','persons','lug_boot','safety','class']
car_data = pd.read_csv('../data/raw/car.data', names=colnames, header=None)

car_data.head()
```

### Data Import and Validation

```{python}
# Validate data schema with Pandera
#Correct data types in each column
#No duplicate observations,
#No outlier or anomalous values, since all of our data are categorical features, no need for this
schema = pa.DataFrameSchema(
    {
        'buying': pa.Column(str, pa.Check.isin(['low','med','high','vhigh']), nullable=False),
        'maint': pa.Column(str, pa.Check.isin(['low','med','high','vhigh']), nullable=False),
        'doors': pa.Column(str, pa.Check.isin(['2','3','4','5more']), nullable=False),
        'persons': pa.Column(str, pa.Check.isin(['2','4','more']), nullable=False),
        'lug_boot': pa.Column(str, pa.Check.isin(['small','med','big']), nullable=False),
        'safety': pa.Column(str, pa.Check.isin(['low','med','high']), nullable=False),
        'class': pa.Column(str, pa.Check.isin(['unacc','acc','vgood','good']), nullable=False)
    },
    checks=[
        pa.Check(lambda car_data: ~car_data.duplicated().any(), error="Duplicate rows found.")
    ]
)
schema.validate(car_data, lazy=True)
```

Data validation checklist:

| Check | Result |
| ----- | ------ |
| Correct data file format | `car.data` does not have the right extension, but can be read in as a `.csv` file |
| Correct column names | `car.data` does not contain column names; column names located in `car.c45-names` and passed into `columns=` argument in `pd.read_csv()` |
| No empty observations | Passed `.validate` checks |
| Missingness not beyond expected threshold | Not applicable; no empty observations (see above) |
| Correct data types in each column | Passed `.validate` checks |
| No duplicate observations | Passed `.validate` checks |
| No outlier or anomalous values | Not applicable; all features are categorical |
| Correct category levels (i.e., no string mismatches or single values) | Passed `.validate` checks |
| Target/response variable follows expected distribution | See Exploratory Data Analysis |
| No anomalous correlations between target/response variable and features/explanatory variables | See Preprocessing of Dataset |
| No anomalous correlations between features/explanatory variables | See Preprocessing of Dataset |


### Exploratory Data Analysis

Exploratory data analysis was carried out on the train dataset.
Here, the counts of records by target and category was visualised to gain a better idea of the dataset.

```{python}
car_data.info()
```

```{python}
# train test split, export to csv
np.random.seed(522)

car_train, car_test = train_test_split(
    car_data, train_size=0.8, random_state=522, stratify=car_data['class']
)

car_train.to_csv('../data/processed/car_train.csv')
car_test.to_csv('../data/processed/car_test.csv')
```

```{python}
alt.Chart(car_train).mark_bar().encode(
    x=alt.X(alt.repeat('row')),
    y='count()',
    color=alt.Color('class'),
    column='class'
).properties(
    height=100
).repeat(
    row=['buying','maint','doors','persons','lug_boot','safety']
)

```
```{python}
test_scores_df = pd.read_csv("../results/tables/test_scores.csv").round(2)
with open('../results/models/car_analysis.pickle', 'rb') as f:
    car_analysis = pickle.load(f)
```
Figure 1: Visualization of counts by feature and target class.
Through this analysis, we can see that examples with target class `unacceptable` represent a large proportion of the dataset.

## Preprocessing of Dataset for Machine Learning
We preprocess the dataset to prepare it for machine learning:
Transform categorical features using`OrdinalEncoder` .
Split the dataset into training and testing sets.

```{python}
# preprocessing

# transform categorical features
car_preprocessor = make_column_transformer(
    (OrdinalEncoder(categories=[['low','med','high','vhigh']]), ['buying']),
    (OrdinalEncoder(categories=[['low','med','high','vhigh']]), ['maint']),
    (OrdinalEncoder(categories=[['2','3','4','5more']]), ['doors']),
    (OrdinalEncoder(categories=[['2','4','more']]), ['persons']),
    (OrdinalEncoder(categories=[['small','med','big']]), ['lug_boot']),
    (OrdinalEncoder(categories=[['low','med','high']]), ['safety']),
    remainder='passthrough',
    verbose_feature_names_out=False
)

car_preprocessor.fit(car_train)
encoded_car_train = car_preprocessor.transform(car_train)
encoded_car_test = car_preprocessor.transform(car_test)

names = car_preprocessor.get_feature_names_out()
encoded_car_train = pd.DataFrame(encoded_car_train, columns=names)
encoded_car_test = pd.DataFrame(encoded_car_test, columns=names)

encoded_car_train.to_csv('../data/processed/encoded_car_train.csv')
encoded_car_test.to_csv('../data/processed/encoded_car_test.csv')
```

```{python}
# Validate feature and target distributions with Deepchecks
categorical_features = ['buying','maint','doors','persons','lug_boot','safety']
car_train_ds = Dataset(car_train, label='class', cat_features=categorical_features)

# Target/response variable follows expected distribution
ClassImbalance().add_condition_class_ratio_less_than(0.15).run(car_train_ds)
```

```{python}
# No anomalous correlations between target/response variable and features/explanatory variables
# No anomalous correlations between features/explanatory variables
corr_threshold = 0.9

check_feat_lab_corr = FeatureLabelCorrelation().add_condition_feature_pps_less_than(corr_threshold)
check_feat_lab_corr_result = check_feat_lab_corr.run(dataset=car_train_ds)

check_feat_feat_corr = FeatureFeatureCorrelation().add_condition_max_number_of_pairs_above_threshold(threshold=corr_threshold, n_pairs=0)
check_feat_feat_corr_result = check_feat_feat_corr.run(dataset=car_train_ds)

if not check_feat_lab_corr_result.passed_conditions():
    raise ValueError("Feature-Label correlation exceeds the maximum acceptable threshold.")

if not check_feat_feat_corr_result.passed_conditions():
    raise ValueError("Feature-feature correlation exceeds the maximum acceptable threshold.")

# print(check_feat_lab_corr_result)
# print(check_feat_feat_corr_result)
```

```{python}
X_train, y_train = car_train.drop(columns=['class']), car_train['class']
X_test, y_test = car_test.drop(columns=['class']), car_test['class']
```

### Model Selection

The core of this project is choosing the appropriate machine learning model. Thus, in the next step, several machine learning models will be evaluated.


`cross_validate` from `sklearn` will be used to evaluate the best performing model.

According to our cross-validation results, 
SVM RBF achieved the highest train and cross-validation scores,
suggesting it is the best model for generalising unseen data. 
Therefore, we will be using SVM RBF for this project.



## 


As the score report has indicated, our model is extremely well, achieving a test accuracy of 0.991. This means that our model is predicting well on unseen data.

## References

* Bohanec, M. (1988). Car Evaluation [Dataset]. _UCI Machine Learning Repository._ (https://doi.org/10.24432/C5JP48).

* Makki, S., Mustapha, A., Kassim, J. M., Gharayebeh, E. H., & Alhazmi, M. (2011, April). Employing neural network and naive Bayesian classifier in mining data for car evaluation. In Proc. _ICGST AIML-11 Conference (pp. 113-119)._

* Potdar, K., Pardawala, T. S., & Pai, C. D. (2017). A comparative study of categorical variable encoding techniques for neural network classifiers. _International journal of computer applications, 175(4), 7-9._

* Tanveer, M., Gautam, C., & Suganthan, P. N. (2019). Comprehensive evaluation of twin SVM based classifiers on UCI datasets. _Applied Soft Computing, 83_, 105617.

* Timbers, T., Ostblom, J., & Lee, M. (2024). Breast Cancer Predictor Report*. GitHub repository. Retrieved from https://github.com/ttimbers/breast_cancer_predictor_py/blob/0.0.1/src/breast_cancer_predictor_report.ipynb


